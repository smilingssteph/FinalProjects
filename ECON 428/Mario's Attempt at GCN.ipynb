{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d4010-ed8c-49d1-86b6-ddcf819f7592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105401a1-2b03-4fb1-9031-eca29a79525a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(\"/Users/mario/Downloads/Graph_State_Uni.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "192da0c0-db43-4748-ad7e-da98d471a5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_clean = df.dropna(subset=['Graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63c3259b-9408-4d10-869c-3fe7ec45c36e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Town</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Search_Place</th>\n",
       "      <th>Graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(AlAMU, 1875)</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>Madison</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>Huntsville, Alabama</td>\n",
       "      <td>(56922621, 56923776, 56923781, 56923787, 56924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(AlAMU, 1875)</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>Montgomery, Alabama</td>\n",
       "      <td>(58878326, 58878327, 58878330, 58878370, 58878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(AubU, 1856)</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>Auburn, Alabama</td>\n",
       "      <td>(56844738, 56844741, 56845079, 56845082, 56845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(AubU, 1856)</td>\n",
       "      <td>Florence</td>\n",
       "      <td>Lauderdale</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>Florence, Alabama</td>\n",
       "      <td>(56540270, 56540280, 56540305, 56540703, 56540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(AubU, 1856)</td>\n",
       "      <td>Talladega</td>\n",
       "      <td>Talladega</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>Talladega, Alabama</td>\n",
       "      <td>(52315445, 52318540, 52326293, 52387532, 52398...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(UWi, 1838)</td>\n",
       "      <td>Madison</td>\n",
       "      <td>Dane</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>Madison, Wisconsin</td>\n",
       "      <td>(29981753, 29983388, 30004443, 30052852, 30052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(UWi, 1838)</td>\n",
       "      <td>Ripon</td>\n",
       "      <td>Fond du Lac</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0</td>\n",
       "      <td>Ripon, Wisconsin</td>\n",
       "      <td>(230969615, 230969647, 230969653, 230972997, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(UWy, 1886)</td>\n",
       "      <td>Laramie</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "      <td>Laramie, Wyoming</td>\n",
       "      <td>(156300705, 156300836, 156300840, 156300844, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(UWy, 1886)</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>Laramie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "      <td>Cheyenne, Wyoming</td>\n",
       "      <td>(157345948, 157345956, 157345970, 157346034, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(UWy, 1886)</td>\n",
       "      <td>Evanston</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "      <td>Evanston, Wyoming</td>\n",
       "      <td>(158240422, 158240425, 158240688, 158240974, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Experiment        Town       County      State  Treatment  \\\n",
       "0    (AlAMU, 1875)  Huntsville      Madison    Alabama          1   \n",
       "1    (AlAMU, 1875)  Montgomery   Montgomery    Alabama          0   \n",
       "3     (AubU, 1856)      Auburn          Lee    Alabama          1   \n",
       "4     (AubU, 1856)    Florence   Lauderdale    Alabama          0   \n",
       "5     (AubU, 1856)   Talladega    Talladega    Alabama          0   \n",
       "..             ...         ...          ...        ...        ...   \n",
       "995    (UWi, 1838)     Madison         Dane  Wisconsin          1   \n",
       "996    (UWi, 1838)       Ripon  Fond du Lac  Wisconsin          0   \n",
       "997    (UWy, 1886)     Laramie       Albany    Wyoming          1   \n",
       "998    (UWy, 1886)    Cheyenne      Laramie    Wyoming          0   \n",
       "999    (UWy, 1886)    Evanston        Uinta    Wyoming          0   \n",
       "\n",
       "            Search_Place                                              Graph  \n",
       "0    Huntsville, Alabama  (56922621, 56923776, 56923781, 56923787, 56924...  \n",
       "1    Montgomery, Alabama  (58878326, 58878327, 58878330, 58878370, 58878...  \n",
       "3        Auburn, Alabama  (56844738, 56844741, 56845079, 56845082, 56845...  \n",
       "4      Florence, Alabama  (56540270, 56540280, 56540305, 56540703, 56540...  \n",
       "5     Talladega, Alabama  (52315445, 52318540, 52326293, 52387532, 52398...  \n",
       "..                   ...                                                ...  \n",
       "995   Madison, Wisconsin  (29981753, 29983388, 30004443, 30052852, 30052...  \n",
       "996     Ripon, Wisconsin  (230969615, 230969647, 230969653, 230972997, 2...  \n",
       "997     Laramie, Wyoming  (156300705, 156300836, 156300840, 156300844, 1...  \n",
       "998    Cheyenne, Wyoming  (157345948, 157345956, 157345970, 157346034, 1...  \n",
       "999    Evanston, Wyoming  (158240422, 158240425, 158240688, 158240974, 1...  \n",
       "\n",
       "[827 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db1564d-d78f-413e-be5e-c75acab8e29b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import ast\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ee3925b-a7d8-4731-907b-f265c11029cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x1e69534eac0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Graph\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848df195-6579-444b-93c9-bbea27204462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49b7fcbb-d404-4b92-a3c0-4b5a6bac3768",
   "metadata": {
    "tags": []
   },
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "def process_graph(row):\n",
    "    # Check if the graph is a valid MultiDiGraph object\n",
    "    G = row['Graph']\n",
    "    \n",
    "    if isinstance(G, nx.MultiDiGraph):\n",
    "        edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "        \n",
    "        # Assuming node features are an identity matrix (one-hot encoding)\n",
    "        x = torch.eye(G.number_of_nodes())\n",
    "        \n",
    "        # Get the treatment label\n",
    "        y = torch.tensor([row['Treatment']], dtype=torch.long)\n",
    "        \n",
    "        return Data(x=x, edge_index=edge_index, y=y)\n",
    "    else:\n",
    "        # Handle cases where the graph is invalid or missing\n",
    "        return None\n",
    "\n",
    "# Applying the function to the DataFrame\n",
    "graphs = [process_graph(row) for idx, row in df.iterrows()]\n",
    "\n",
    "# Remove None values from the list\n",
    "graphs = [g for g in graphs if g is not None]\n",
    "\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data = train_test_split(graphs, test_size=0.2)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50b95d-524e-4135-873e-1d6279700c6f",
   "metadata": {},
   "source": [
    "## to adjust for node features matrix being to large to fit into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b4e9c84-7daa-41e8-85b6-017dd10c3dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_graph(row):\n",
    "    G = row['Graph']\n",
    "    \n",
    "    if isinstance(G, nx.MultiDiGraph):\n",
    "        edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "        \n",
    "        # Node features are simply node indices instead of one-hot encoding\n",
    "        num_nodes = G.number_of_nodes()\n",
    "        node_indices = torch.arange(num_nodes).unsqueeze(1)\n",
    "        \n",
    "        y = torch.tensor([row['Treatment']], dtype=torch.long)\n",
    "        \n",
    "        return Data(x=node_indices, edge_index=edge_index, y=y)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "graphs = [process_graph(row) for idx, row in df_clean.iterrows()]\n",
    "\n",
    "# Remove None values from the list\n",
    "graphs = [g for g in graphs if g is not None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff3ff8-86c0-4a14-88dc-c6e3ff6ad994",
   "metadata": {},
   "source": [
    "## Shows Node Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4fa329-24e3-4429-9605-d6159c285d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, data in enumerate(graphs):\n",
    "#    print(f\"Graph {idx}: Nodes = {data.num_nodes}, Edges = {data.edge_index.size()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d259a753-7e75-4823-8f6a-f1f9e2a22843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_features, hidden_features)\n",
    "        self.conv2 = GCNConv(hidden_features, out_features)\n",
    "        self.clf = nn.Linear(out_features, 2)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.clf(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3eaf0efc-2d42-4e3a-b384-d4012447d5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 3 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 14\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out[data\u001b[38;5;241m.\u001b[39mtrain_mask], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[65], line 10\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch_geometric\\utils\\loop.py:654\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[0;32m    652\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n\u001b[1;32m--> 654\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch_geometric\\edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;66;03m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[1;32m-> 1057\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHANDLED_FUNCTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;66;03m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m     _types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(Tensor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch_geometric\\edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[1;34m(tensors, dim, out)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1204\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\_tensor.py:1121\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[1;32m-> 1121\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 3 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "model = GCN(in_features=9000, hidden_features= 64, out_features= 2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Change for results\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1786dc6-f53b-47f8-808a-3909c69313f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_graph(row):\n",
    "    G = nx.Graph()  # Use Graph for undirected or DiGraph for directed graphs\n",
    "\n",
    "    # Assuming 'row['Graph']' is a list of edges (e.g., [(src1, dst1), (src2, dst2), ...])\n",
    "    edges = ast.literal_eval(row['Graph'])\n",
    "\n",
    "    G.add_edges_from(edges)\n",
    "    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "    if edge_index.size(0) != 2:\n",
    "        print(\"Unexpected edge index size:\", edge_index.size())\n",
    "    \n",
    "    # Process node features and labels as appropriate\n",
    "    return Data(x=..., edge_index=edge_index, y=...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39ce2d-b8ef-41ce-b152-57ac14f9ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "for data in test_loader:\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct += (pred == data.y).sum().item()\n",
    "\n",
    "accuracy = correct / len(test_loader.dataset)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b496d5a2-562e-4dbb-bbfa-be032bd256a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load(\"data/training/graphcnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d4cdac-3193-4fd3-a088-659310d86743",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GCN:\n\tMissing key(s) in state_dict: \"conv1.bias\", \"conv1.lin.weight\", \"conv2.bias\", \"conv2.lin.weight\", \"clf.weight\", \"clf.bias\". \n\tUnexpected key(s) in state_dict: \"gcn1.linear.weight\", \"gcn1.linear.bias\", \"gcn2.linear.weight\", \"gcn2.linear.bias\", \"attention_pool.attention_dense.weight\", \"attention_pool.attention_dense.bias\", \"attention_pool.score_dense.weight\", \"attention_pool.score_dense.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9000\u001b[39m, hidden_features\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, out_features\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GCN:\n\tMissing key(s) in state_dict: \"conv1.bias\", \"conv1.lin.weight\", \"conv2.bias\", \"conv2.lin.weight\", \"clf.weight\", \"clf.bias\". \n\tUnexpected key(s) in state_dict: \"gcn1.linear.weight\", \"gcn1.linear.bias\", \"gcn2.linear.weight\", \"gcn2.linear.bias\", \"attention_pool.attention_dense.weight\", \"attention_pool.attention_dense.bias\", \"attention_pool.score_dense.weight\", \"attention_pool.score_dense.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". "
     ]
    }
   ],
   "source": [
    "model = GCN(in_features=9000, hidden_features= 64, out_features= 2)\n",
    "model.load_state_dict(model_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
